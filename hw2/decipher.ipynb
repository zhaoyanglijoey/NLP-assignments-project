{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start method already set to spawn!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local-scratch2/anaconda3/lib/python3.6/site-packages/tqdm/autonotebook/__init__.py:14: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  \" (e.g. in jupyter console)\", TqdmExperimentalWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict, Counter\n",
    "import collections\n",
    "import pprint\n",
    "import math\n",
    "import bz2\n",
    "import string\n",
    "import argparse\n",
    "from ngram import LM\n",
    "from nlm_scorer import NlmScorer\n",
    "import nlm\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "# from multiprocessing import Pool\n",
    "import torch\n",
    "from torch.multiprocessing import Pool, set_start_method\n",
    "\n",
    "try:\n",
    "    torch.multiprocessing.set_start_method('spawn')\n",
    "except RuntimeError:\n",
    "    print('Start method already set to spawn!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading language model from data/6-gram-wiki-char.lm.bz2...\n",
      "Done.\n",
      "Loading model data/mlstm_ns.pt..\n",
      "Model on board!\n"
     ]
    }
   ],
   "source": [
    "lm = LM(\"data/6-gram-wiki-char.lm.bz2\", n=6, verbose=False)\n",
    "model = nlm.load_model(\"data/mlstm_ns.pt\", cuda=False)\n",
    "nlm = NlmScorer(model, cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    if filename[-4:] == \".bz2\":\n",
    "        with bz2.open(filename, 'rt') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    else:\n",
    "        with open(filename, 'r') as f:\n",
    "            content = f.read()\n",
    "            f.close()\n",
    "    return content\n",
    "\n",
    "def check_limits(mappings, ext_limits, letter_to_check=0):\n",
    "    if letter_to_check is None:\n",
    "        targets = mappings.values()\n",
    "        counts = Counter(targets).values()\n",
    "        if any([count > ext_limits for count in counts]):\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "    else:\n",
    "        plaintext_letters = list(mappings.values())\n",
    "        return plaintext_letters.count(letter_to_check) <= ext_limits\n",
    "\n",
    "def score_single_seq(t):\n",
    "    i, seq = t\n",
    "    # if len(seq) >= 20:\n",
    "    #     print('Scoring:', seq)\n",
    "    # return lm.score_seq(seq) if len(seq) < 20 else nlm.score_seq(seq)\n",
    "    return lm.score_patial_seq(seq) if i != 0 else lm.score_seq(seq)\n",
    "\n",
    "pool = Pool(12)\n",
    "\n",
    "def score(mappings, cipher_text, lm, nlm):\n",
    "    deciphered = [mappings[cipher_letter] if cipher_letter in mappings else ' ' for cipher_letter in cipher_text]\n",
    "    deciphered = ''.join(deciphered)\n",
    "    # bit_string = [ 'o' if c in mappings else '.' for c in cipher_text]\n",
    "    # bit_string = ''.join(bit_string)\n",
    "    seqs = deciphered.split()\n",
    "\n",
    "    res = sum(pool.map(score_single_seq, zip(range(len(seqs)),seqs)))\n",
    "\n",
    "    # return lm.score_bitstring(deciphered, bit_string)\n",
    "    return res\n",
    "\n",
    "def prune(beams, beamsize):\n",
    "    sorted_beams = sorted(beams, key=lambda b: b[1], reverse=True)\n",
    "\n",
    "    return sorted_beams[:beamsize]\n",
    "\n",
    "\n",
    "def beam_search(cipher_text, lm, nlm, ext_order, ext_limits, init_beamsize):\n",
    "    Hs = []\n",
    "    Ht = []\n",
    "    cardinality = 0\n",
    "    Hs.append(({}, 0))\n",
    "    Ve = string.ascii_lowercase\n",
    "    scorer = lm\n",
    "\n",
    "    while cardinality < len(ext_order):\n",
    "        beamsize = int(init_beamsize*(0.94**cardinality))\n",
    "#         beamsize = init_beamsize\n",
    "        # if cardinality > 10:\n",
    "        #     scorer = nlm\n",
    "        print(\"Searching for {}/{} letter\".format(cardinality, len(ext_order)))\n",
    "        print(\"Current size of searching tree: {}\".format(len(Hs)))\n",
    "        cipher_letter = ext_order[cardinality]\n",
    "        for mappings, sc in Hs:\n",
    "            for plain_letter in Ve:\n",
    "                ext_mappings = deepcopy(mappings)\n",
    "                ext_mappings[cipher_letter] = plain_letter\n",
    "                if check_limits(ext_mappings, ext_limits, plain_letter):  # only check new added one\n",
    "                    Ht.append((ext_mappings, score(ext_mappings, cipher_text, lm, nlm)))\n",
    "        Hs = prune(Ht, beamsize)\n",
    "        cardinality += 1\n",
    "        Ht = []\n",
    "        # print(Hs)\n",
    "    Hs.sort(key=lambda b: b[1], reverse=True)\n",
    "    # pp.pprint(Hs)\n",
    "    return Hs[0]\n",
    "\n",
    "def contiguous_score(cipher, order):\n",
    "    order = set(order)\n",
    "    count = 0\n",
    "    ngrams = defaultdict(int)\n",
    "    for c in cipher:\n",
    "        if c in order:\n",
    "            if count == 8:\n",
    "                ngrams[count] += 1\n",
    "            else:\n",
    "                count += 1\n",
    "        else:\n",
    "            if count != 0:\n",
    "                ngrams[count] += 1\n",
    "            count = 0\n",
    "    if count != 0:\n",
    "        ngrams[count] += 1\n",
    "    weights = [0, 0, 1, 1, 1, 1, 1, 2, 3]\n",
    "    score = 0\n",
    "    for k, v in ngrams.items():\n",
    "        score += weights[k] * v\n",
    "    return score\n",
    "\n",
    "def prune_orders(orders, beamsize):\n",
    "    sorted_order = sorted(orders, reverse=True)\n",
    "\n",
    "    return sorted_order[: beamsize]\n",
    "\n",
    "def search_ext_order(cipher, beamsize):\n",
    "    symbols = set(cipher)\n",
    "    freq = Counter(cipher)\n",
    "    start = ''\n",
    "    maxf = 0\n",
    "    for symbol, f in freq.items():\n",
    "        if f > maxf:\n",
    "            maxf = f\n",
    "            start = symbol\n",
    "    orders = [([0], [start])]\n",
    "    orders_tmp = []\n",
    "    symbols.remove(start)\n",
    "    for i in range(len(symbols)):\n",
    "        for scores, order in orders:\n",
    "            for symbol in symbols:\n",
    "                if symbol not in order:\n",
    "                    new_order = deepcopy(order)\n",
    "                    new_order.append(symbol)\n",
    "                    new_scores = deepcopy(scores)\n",
    "                    new_scores.insert(0, contiguous_score(cipher, new_order))\n",
    "                    orders_tmp.append((new_scores, new_order))\n",
    "        orders = prune_orders(orders_tmp, beamsize)\n",
    "        orders_tmp = []\n",
    "        # pp.pprint(orders)\n",
    "    orders.sort(reverse=True)\n",
    "    # pp.pprint(orders)\n",
    "    return orders[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start deciphering...\n",
      "Searching for 0/54 letter\n",
      "Current size of searching tree: 1\n",
      "Searching for 1/54 letter\n",
      "Current size of searching tree: 26\n",
      "Searching for 2/54 letter\n",
      "Current size of searching tree: 676\n",
      "Searching for 3/54 letter\n",
      "Current size of searching tree: 17576\n",
      "Searching for 4/54 letter\n",
      "Current size of searching tree: 456976\n"
     ]
    }
   ],
   "source": [
    "cipher = read_file('data/cipher.txt')\n",
    "cipher = [x for x in cipher if not x.isspace()]\n",
    "cipher = ''.join(cipher)\n",
    "ext_order = search_ext_order(cipher, 100)\n",
    "ext_limits = 8\n",
    "beamsize = 1000000\n",
    "\n",
    "print('Start deciphering...')\n",
    "search_start = datetime.now()\n",
    "mappings, sc = beam_search(cipher, lm, nlm, ext_order, ext_limits, beamsize)\n",
    "search_end = datetime.now()\n",
    "print('Deciphering completed after {}'.format(search_end - search_start))\n",
    "print('Mappings: ', mappings)\n",
    "deciphered = [mappings[c] if c in mappings else '_' for c in cipher]\n",
    "deciphered = ''.join(deciphered)\n",
    "print('Decipherment: {} \\nscore: {}'.format(deciphered, sc))\n",
    "\n",
    "\n",
    "def read_gold(gold_file):\n",
    "    with open(gold_file) as f:\n",
    "        gold = f.read()\n",
    "    f.close()\n",
    "    gold = list(gold.strip())\n",
    "    return gold\n",
    "\n",
    "def symbol_error_rate(dec, _gold):\n",
    "    gold = read_gold(_gold)\n",
    "    correct = 0\n",
    "    if len(gold) == len(dec):\n",
    "        for (d,g) in zip(dec, gold):\n",
    "            if d==g:\n",
    "                correct += 1\n",
    "    wrong = len(gold)-correct\n",
    "    error = wrong/len(gold)\n",
    "    \n",
    "    return error\n",
    "    \n",
    "# gold decipherment\n",
    "gold_file = \"data/ref.txt\"\n",
    "ser = symbol_error_rate(deciphered, gold_file)\n",
    "print('Error: ', ser*100, 'Accuracy: ', (1-ser)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
