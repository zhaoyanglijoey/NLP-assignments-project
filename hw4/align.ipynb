{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this homework we tried two models for alignment:\n",
    "\n",
    "- IBM Model 1\n",
    "- HMM model\n",
    "\n",
    "And we apply bidirectional alignment training and decoding for both models. We found that by applying the pretrained parameters in IBM model 1 into HMM model, we got relatively nice **AER -- 0.11FIXME** only training for FIXME iterations in HMM.\n",
    "\n",
    "## Baseline (IBM model 1)\n",
    "\n",
    "For each English-French word pair, we have $t(f|e)$, which is initially $1/|f|$.\n",
    "\n",
    "For each iteration, we:\n",
    "\n",
    "* initial count() and count_pair() to 0\n",
    "* for each parallel sentence pair $(f,e)$\n",
    " * for each French word $f_i$\n",
    " * $z = \\sum_{e_j} t(f_i|e_j)$\n",
    "  * for each English word $e_j$\n",
    "   * $c = t(f_i|e_j) / z$\n",
    "   * $count\\_pair(f_i|e_j) += c$\n",
    "   * $count(e_j) += c$\n",
    "* for each word pair (f,e) in count_pair()\n",
    " * $t(f|e) = count\\_pair(f|e) / count_e(e)$\n",
    "\n",
    "Repeat the process until the difference between the new log likelihood and the previous one is smaller than a fixed value epsilon or until we have run a fixed number of iterations.\n",
    "\n",
    "#### Result\n",
    "\n",
    "After 8 iterations:\n",
    "* Precision = 0.599407\n",
    "* Recall = 0.773403\n",
    "* AER = 0.341046\n",
    "\n",
    "## Improvements\n",
    "\n",
    "### Bidirectional IBM model 1 (align using $Pr(f|e)$ and $Pr(e|f)$)\n",
    "\n",
    "Align using $Pr(f|e)$ and also align using $Pr(e|f)$. Then decode the best alignment using each model independently. Then report the alignments that are the intersection of these two alignment sets.\n",
    "\n",
    "#### Result\n",
    "\n",
    "After 100 iterations:\n",
    "* Precision = 0.867216\n",
    "* Recall = 0.695146\n",
    "* AER = 0.220469\n",
    "\n",
    "#### Analysis\n",
    "\n",
    "We can see that by intersecting the decoding results of two alignment directions, we got much higher precision but lower recall. This means we discarded many good results which do not appear in the intersections. There are ways to improve both precision and recall by intersecting during training (Liang et al.)\n",
    "\n",
    "### HMM-based alignment model\n",
    "\n",
    "\n",
    "\n",
    "#### Result\n",
    "\n",
    "After 4 iterations:\n",
    "* Precision = 0.731220\n",
    "* Recall = 0.862803\n",
    "* AER = 0.223748\n",
    "\n",
    "### Combine HMM-based alignment model with bidirectional IBM model 1\n",
    "\n",
    "#### Result\n",
    "\n",
    "After 3 iteration:\n",
    "* Precision = 0.949554\n",
    "* Recall = 0.820456\n",
    "* AER = 0.113253"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] \"IBM Models\". SMT Research Survey Wiki. 11 September 2015. Retrieved 20 Nov 2018.\n",
    "[2]  P. Liang, B. Taskar, and D. Klein. Alignment by agreement. In NAACL. 2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precision = 0.949554\n",
      "Recall = 0.820456\n",
      "AER = 0.113253\n"
     ]
    }
   ],
   "source": [
    "import argparse, sys, os, logging\n",
    "from itertools import islice\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from HMMmodel import BiHMMmodel, score_alignments\n",
    "f_data = \"data/hansards.fr\"\n",
    "e_data = \"data/hansards.en\"\n",
    "a_data = \"data/hansards.a\"\n",
    "with open(f_data) as f, open(e_data) as e, open(a_data) as a:\n",
    "    f_data, e_data, a_data = f.readlines(),\\\n",
    "                             e.readlines(), \\\n",
    "                             a.readlines()\n",
    "\n",
    "bitext = [[sentence.strip().split() for sentence in pair] for pair in \n",
    "    zip(f_data, e_data)]\n",
    "rev_bitext = [[e_sentence, f_setence] for f_setence, e_sentence in bitext]\n",
    "bihmmmodel = BiHMMmodel()\n",
    "bihmmmodel.load_model('bihmmckpt/bihmm_iter3.m')\n",
    "bihmmmodel.validate(bitext, rev_bitext, f_data, e_data, a_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
